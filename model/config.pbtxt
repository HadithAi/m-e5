 name: "model"
 backend: "onnxruntime_onnx"
 max_batch_size: 0  # Set to >0 if you want batching

 input [
   {
     name: "INPUT"
     data_type: TYPE_FP32
     dims: [ -1 ]
   }
 ]

 output [
   {
     name: "OUTPUT"
     data_type: TYPE_UINT8
     dims: [ -1 ]
   }
 ]

 instance_group [
   {
     count: 2 # with this we can make it scale Horizantally
     kind: KIND_CPU
   }
 ]


dynamix_batching {
	max_queu_delay_microseconds: 0
}
